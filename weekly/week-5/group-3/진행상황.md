# 3조 (sPRinter) 진행상황

## 과제 선정

- PR Agent 오픈소스에 기여하기 위한 주제로 **`algo` 폴더 리팩토링**을 선정

![Screenshot from 2025-05-18 15-51-24.png](attachment:f7219b6c-fc9d-472d-825d-b5b2f5c6dbc2:Screenshot_from_2025-05-18_15-51-24.png)

- algo 폴더
  - PR Agent의 **핵심 로직이** 집중된 디렉토리
  - 주요 기능을 구성하는 알고리즘, 유틸 함수, AI 모델과의 상호작용 핸들러 포함
- algo 폴더의 문제점
  - 코드 가독성이 낮음
  - 함수 책임이 명확하지 않음
  - 테스트 커버리지 부족
  - 구조 확장 및 유지보수가 어려움

---

## 진행 과정

- 조원 각각 algo 폴더를 분석하고 문제점들 조사
- 오프라인 모임 진행
  - 일자: 5월 15일 (목)
  - 장소: 서초 OpenUp 회의실
  - 주요 안건: 개별 조사 공유 및 진행 방향 설정

![20250515_192115.jpg](attachment:6e3ad061-08af-4cc5-91d8-3a8c8dd6d2c9:20250515_192115.jpg)

![20250515_192105.jpg](attachment:fe341576-3f90-471b-a7a3-9a82461b2066:20250515_192105.jpg)

### 공통 목표 설정

- 오픈소스 기여의 전 과정을 직접 경험
  - 이슈 등록 → PR 작성 → 리뷰 → 최종 제출
- 기여 과정을 통해 조원 간 지식과 인사이트 공유

### 진행 방향성 설정

5주차:

1. 조원 각자가 선정한 주제에 대해 `qodo-ai/pr-agent` 저장소에 이슈 등록

6주차:

1. 각각 `qodo-ai/pr-agent` 올린 이슈에 대한 PR을 `ossca-2025/pr-agent`에 업로드
2. PR 작성 후, 팀원 간 24시간 내 상호 리뷰(코멘트 1개 이상) 진행
3. PR 수정 보완 및 멘토님 피드백
4. 최종 PR을 `qodo-ai/pr-agent`에 제출

### 이슈 주제 선정

- AI Handler (/ai_handlers)
  - 강경만 - `token_handler.py coutn_tokens` 메소드 리팩토링
  - 서강문 - 일관적이지 않은 `@retry` import 및 호출 문제 해결
  - 이승민 - `langchain_ai_handler.py`
- utils
  - 박성호 - `load_yaml` 로깅 개선
  - 손찬우 - `convert_to_markdown_v2` 테스트 케이스 추가
  - 장현상 - `pr_processing.py generate_full_patch()`함수 기능 분해

### token_handler.py

- `token_handler.py`의 `count_tokens` 메서드 리팩토링
- 기존 방식
  - `force_accurate` 플래그에 따른 조건 분기
  - 모델 타입 체크
  - 모델별 토큰 계산 함수로의 분기
  - 분기 처리가 조건문에 직접적으로 구현되어 있음

```python
# as-is
def count_tokens(self, patch: str, force_accurate=False) -> int:
   """
   Counts the number of tokens in a given patch string.
 
   Args:
   - patch: The patch string.
 
   Returns:
   The number of tokens in the patch string.
   """
   encoder_estimate = len(self.encoder.encode(patch, disallowed_special=()))
 
   #If an estimate is enough (for example, in cases where the maximal allowed tokens is way below the known limits), return it.
   if not force_accurate:
       return encoder_estimate
 
   #else, force_accurate==True: User requested providing an accurate estimation:
   model = get_settings().config.model.lower()
   if 'claude' in model and get_settings(use_context=False).get('anthropic.key'):
       return self.calc_claude_tokens(patch) # API call to Anthropic for accurate token counting for Claude models
 
   #else: Non Anthropic provided model:
   return self.estimate_token_count_for_non_anth_claude_models(model, encoder_estimate)
```

- 문제점
  - 직접적인 조건문을 통해 **클로드 모델**과 **비클로드 모델**을 구분
  - 추가 모델을 지원할 때 **로직 분기 복잡**해짐
- 개선 방향
  - 정확한 계산 분기를 `determine_accurate_token_count()`로 위임
  - 조건 분기를 별도 메서드로 분리해 가독성과 확장성 확보

```python
# to-be
def count_tokens(self, patch: str, force_accurate: bool = False) -> int:
   """
   Counts the number of tokens in a given patch string.
 
   Args:
   - patch: The patch string.
   - force_accurate: If True, uses a more precise calculation method.
 
   Returns:
   The number of tokens in the patch string.
   """
   encoder_estimate = len(self.encoder.encode(patch, disallowed_special=()))
 
   #If an estimate is enough (for example, in cases where the maximal allowed tokens is way below the known limits), return it.
   if not force_accurate:
       return encoder_estimate
   else:
       return self.determine_accurate_token_count(patch, encoder_estimate=encoder_estimate)
```

메인테이너 피드백

- “현재 방식은 다소 hacky하며, 다양한 모델을 더 잘 지원하는 방향으로 개선하는 것이 타당하다” ([이슈 링크](https://github.com/qodo-ai/pr-agent/issues/1782#:~:text=Sounds%20reasonable%20to%20add%20better%20support%20for%20different%20models%20for%20counting%20tokens.%20the%20current%20way%20is%20indeed%20a%20bit%20%27hacky%27))

### LangChainOpenAIHandler

- 개선 1: langchain 의존성 처리 개선

    ```python
    try:
        from langchain_core.messages import HumanMessage, SystemMessage
        from langchain_openai import AzureChatOpenAI, ChatOpenAI
    except:
        pass  # langchain이 설치 안 되어 있어도 무시
    ```

  - 문제점
    - 의존성 누락 시 아무 메시지 없이 통과
    - 이후 런타임 에러 발생 → 디버깅 어려움
  - 대안
    - `LANGCHAIN_AVAILABLE` 플래그 도입
    - `__init__()`에서 값 체크 후, 명확한 `ImportError` 발생
        > "langchain 및 langchain-openai 패키지가 필요합니다"
- 개선 2: `chat_completion()` 시그니처 통일

    ```python
    # BaseAiHandler
    async def chat_completion(..., img_path: str = None)
    
    # LangChainOpenAIHandler
    async def chat_completion(...):  # ❌ img_path 없음
    ```

  - 문제점
    - 상위 클래스에서 `img_path` 인자를 받지만, 하위 클래스에서 무시
    - 리스코프 치환 원칙(LSP) 위반 → `TypeError` 발생 가능

    ```python
    # ❌ unexpected keyword argument 오류
    LangChainOpenAIHandler.chat_completion(..., img_path="...") 
    ```

  - 개선 방향
    - `img_path: Optional[str] = None` 추가
    - 이미지가 전달될 경우, 해당 핸들러는 이미지 미지원임을 로그로 경고

메인테이너 피드백

- “기존 기능을 유지하면서 단순하고 신뢰성 있게 개선하는 PR은 환영”
- “langchain 핸들러는 커뮤니티 기여 코드이므로, 변경 시 안정성을 최우선 고려”
- ([이슈 링크](https://github.com/qodo-ai/pr-agent/issues/1784#:~:text=The%20langchain_ai_handler%20is,the%20existing%20abilities))

## 정리

- PR Agent의 `algo` 폴더를 리팩토링 과제로 선정
- 조원별 사전 조사 후, 오프라인 모임에서 **공통 목표와 진행 방식** 결정
- 5주차: 조원 각자가 선정한 주제에 대해 `qodo-ai/pr-agent` 저장소에 이슈 등록
- 6주차: 내부 코드 리뷰를 위해 `ossca-2025/pr-agent`에 PR 등록 → 멘토님 피드백 반영 후, 최종 PR을 `qodo-ai/pr-agent` 저장소에 제출 예정
